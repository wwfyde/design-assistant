# type: ignore[import]
import json
import traceback
from typing import Any, Awaitable, Callable, Dict, List, Optional

from langchain_core.messages import (
    AIMessageChunk,
    ToolCall,
    ToolMessage,
    convert_to_openai_messages,
)
from langgraph.graph.state import CompiledStateGraph
from sqlalchemy.orm import Session

from api.core.db import async_session, engine
from api.core.memory import memory_store
from api.services.chat import ChatService, InMemoryChatRepo, PostgresChatRepo
from lib import settings


class StreamProcessor:
    """æµå¼å¤„ç†å™¨ - è´Ÿè´£å¤„ç†æ™ºèƒ½ä½“çš„æµå¼è¾“å‡º"""

    def __init__(
        self,
        session_id: str,
        websocket_service: Callable[[str, Dict[str, Any]], Awaitable[None]],
    ):
        self.session_id = session_id
        self.websocket_service = websocket_service
        self.tool_calls: List[ToolCall] = []
        self.last_saved_message_index = 0
        self.last_streaming_tool_call_id: Optional[str] = None

    async def process_stream(
        self,
        supervisor: CompiledStateGraph,
        messages: List[Dict[str, Any]],
        context: Dict[str, Any],
    ) -> None:
        """å¤„ç†æ•´ä¸ªæµå¼å“åº”

        Args:
            supervisor: æ™ºèƒ½ä½“ç¾¤ç»„
            messages: æ¶ˆæ¯åˆ—è¡¨
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
        """

        # agent = supervisor.compile()
        print(f"ç”¨æˆ·æ¶ˆæ¯: {messages}")
        # print("æµ‹è¯•")

        async for chunk in supervisor.astream(
            {"messages": messages},
            config=context,
            stream_mode=["messages", "custom", "values"],
        ):
            # print(chunk)
            await self._handle_chunk(chunk)

        # å‘é€å®Œæˆäº‹ä»¶
        print("å‘é€å®Œäº‹ä»¶")
        await self.websocket_service(self.session_id, {"type": "done"})

    async def _handle_chunk(self, chunk: Any) -> None:
        # print('ğŸ‘‡chunk', chunk)
        """å¤„ç†å•ä¸ªchunk"""
        chunk_type = chunk[0]

        if chunk_type == "values":
            await self._handle_values_chunk(chunk[1])
        else:
            await self._handle_message_chunk(chunk[1][0])

    async def _handle_values_chunk(self, chunk_data: Dict[str, Any]) -> None:
        """å¤„ç† values ç±»å‹çš„ chunk"""

        # TODO è¿™é‡Œæ˜¯langchainä¸­ç»´æŠ¤çš„æ¶ˆæ¯åˆ—è¡¨

        all_messages = chunk_data.get("messages", [])
        # print(f"{all_messages=}")
        oai_messages = convert_to_openai_messages(all_messages, include_id=False)
        # print(f"{oai_messages=}")
        # ç¡®ä¿ oai_messages æ˜¯åˆ—è¡¨ç±»å‹
        if not isinstance(oai_messages, list):
            oai_messages = [oai_messages] if oai_messages else []

        # å‘é€æ‰€æœ‰æ¶ˆæ¯åˆ°å‰ç«¯
        # print("å‘é€: ", oai_messages)
        await self.websocket_service(self.session_id, {"type": "all_messages", "messages": oai_messages})

        # ä¿å­˜æ–°æ¶ˆæ¯åˆ°æ•°æ®åº“
        async with async_session() as asession:
            with Session(engine) as session:
                if settings.repo_type == "in-memory":
                    chat_service = ChatService(InMemoryChatRepo(memory_store))
                elif settings.repo_type == "postgres":
                    chat_service = ChatService(PostgresChatRepo(session=session, asession=asession))
                else:
                    chat_service = ChatService(InMemoryChatRepo(memory_store))

                # è·å–æœ€è¿‘ä¿å­˜æ¶ˆæ¯çš„lc_id
                last_saved_index = next(
                    (i for i in range(len(oai_messages) - 1, -1, -1) if oai_messages[i]["role"] == "user"),
                    None,
                )

                for oai_message, message in zip(
                    oai_messages[last_saved_index + 1 :],
                    all_messages[last_saved_index + 1 :],
                ):
                    # print(f"assistant message {message=}")
                    chat_service.create_message(
                        self.session_id,
                        oai_message.get("role", "user"),  # message.role or "user",
                        json.dumps(oai_message, ensure_ascii=False),
                        message_id=message.id if not message.id.startswith("lc_run--") else None,
                        lc_id=message.id,
                        # getattr(all_messages[i], "id", None) if i < len(all_messages) else None,  # langchainç”Ÿæˆçš„id ä¸è§„èŒƒ, æˆ–è€…æ›¿æ¢lc_run---
                    )

    async def _handle_message_chunk(self, ai_message_chunk: AIMessageChunk) -> None:
        """å¤„ç†æ¶ˆæ¯ç±»å‹çš„ chunk"""
        # print('ğŸ‘‡ai_message_chunk', ai_message_chunk)
        try:
            content = ai_message_chunk.content

            if isinstance(ai_message_chunk, ToolMessage):
                # å·¥å…·è°ƒç”¨ç»“æœä¹‹åä¼šåœ¨ values ç±»å‹ä¸­å‘é€åˆ°å‰ç«¯ï¼Œè¿™é‡Œä¼šæ›´å¿«å‡ºç°ä¸€äº›
                oai_message = convert_to_openai_messages([ai_message_chunk])[0]
                # print("ğŸ‘‡toolcall res oai_message", oai_message)
                await self.websocket_service(
                    self.session_id,
                    {
                        "type": "tool_call_result",
                        "id": ai_message_chunk.tool_call_id,
                        "message": oai_message,
                    },
                )
            elif content:
                # å‘é€æ–‡æœ¬å†…å®¹
                await self.websocket_service(self.session_id, {"type": "delta", "text": content})
            elif (
                hasattr(ai_message_chunk, "tool_calls")
                and ai_message_chunk.tool_calls
                and ai_message_chunk.tool_calls[0].get("name")
            ):
                # å¤„ç†å·¥å…·è°ƒç”¨
                await self._handle_tool_calls(ai_message_chunk.tool_calls)

            # å¤„ç†å·¥å…·è°ƒç”¨å‚æ•°æµ
            if hasattr(ai_message_chunk, "tool_call_chunks"):
                await self._handle_tool_call_chunks(ai_message_chunk.tool_call_chunks)
        except Exception as e:
            print("ğŸŸ error", e)
            traceback.print_stack()

    async def _handle_tool_calls(self, tool_calls: List[ToolCall]) -> None:
        """å¤„ç†å·¥å…·è°ƒç”¨"""
        self.tool_calls = [tc for tc in tool_calls if tc.get("name")]
        print("ğŸ˜˜tool_call event", tool_calls)

        # éœ€è¦ç¡®è®¤çš„å·¥å…·åˆ—è¡¨
        TOOLS_REQUIRING_CONFIRMATION = {
            # 'generate_video_by_kling_v2_jaaz',
            # 'generate_video_by_seedance_v1_pro_volces',
            # 'generate_video_by_seedance_v1_lite_i2v',
            # 'generate_video_by_seedance_v1_lite_t2v',
            # 'generate_video_by_seedance_v1_jaaz',
            # 'generate_video_by_hailuo_02_jaaz',
            "generate_video_by_veo3_fast_jaaz",
        }

        for tool_call in self.tool_calls:
            tool_name = tool_call.get("name")

            # æ£€æŸ¥æ˜¯å¦éœ€è¦ç¡®è®¤
            if tool_name in TOOLS_REQUIRING_CONFIRMATION:
                # å¯¹äºéœ€è¦ç¡®è®¤çš„å·¥å…·ï¼Œä¸åœ¨è¿™é‡Œå‘é€äº‹ä»¶ï¼Œè®©å·¥å…·å‡½æ•°è‡ªå·±å¤„ç†
                print(f"ğŸ”„ Tool {tool_name} requires confirmation, skipping StreamProcessor event")
                continue
            else:
                await self.websocket_service(
                    self.session_id,
                    {
                        "type": "tool_call",
                        "id": tool_call.get("id"),
                        "name": tool_name,
                        "arguments": "{}",
                    },
                )

    async def _handle_tool_call_chunks(self, tool_call_chunks: List[Any]) -> None:
        """å¤„ç†å·¥å…·è°ƒç”¨å‚æ•°æµ"""
        for tool_call_chunk in tool_call_chunks:
            if tool_call_chunk.get("id"):
                # æ ‡è®°æ–°çš„æµå¼å·¥å…·è°ƒç”¨å‚æ•°å¼€å§‹
                self.last_streaming_tool_call_id = tool_call_chunk.get("id")
            else:
                if self.last_streaming_tool_call_id:
                    await self.websocket_service(
                        self.session_id,
                        {
                            "type": "tool_call_arguments",
                            "id": self.last_streaming_tool_call_id,
                            "text": tool_call_chunk.get("args"),
                        },
                    )
                else:
                    print("ğŸŸ no last_streaming_tool_call_id", tool_call_chunk)
