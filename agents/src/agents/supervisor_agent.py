from agents.creative_assitant import build_creative_assistant
from api.core.memory import memory_checkpointer
from api.core.StreamProcessor import StreamProcessor
from api.domain.model import ModelInfo
from api.domain.tool import ToolInfo
from api.services.websocket import send_to_websocket

from lib import settings

supervisor_prompt = """You are a supervisor managing two agents"""


import traceback
from typing import Any, Dict, List, Set, TypedDict, cast

from langchain_openai import ChatOpenAI

# from services.websocket_service import send_to_websocket  # type: ignore


class ContextInfo(TypedDict):
    """Context information passed to tools"""

    canvas_id: str
    session_id: str
    model_info: Dict[str, List[ModelInfo]]


def _fix_chat_history(messages: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """ä¿®å¤èŠå¤©å†å²ä¸­ä¸å®Œæ•´çš„å·¥å…·è°ƒç”¨

    æ ¹æ®LangGraphæ–‡æ¡£å»ºè®®ï¼Œç§»é™¤æ²¡æœ‰å¯¹åº”ToolMessageçš„tool_calls
    å‚è€ƒ: https://langchain-ai.github.io/langgraph/troubleshooting/errors/INVALID_CHAT_HISTORY/
    """
    if not messages:
        return messages

    fixed_messages: List[Dict[str, Any]] = []
    tool_call_ids: Set[str] = set()

    # ç¬¬ä¸€éï¼šæ”¶é›†æ‰€æœ‰ToolMessageçš„tool_call_id
    for msg in messages:
        if msg.get("role") == "tool" and msg.get("tool_call_id"):
            tool_call_id = msg.get("tool_call_id")
            if tool_call_id:
                tool_call_ids.add(tool_call_id)

    # ç¬¬äºŒéï¼šä¿®å¤AIMessageä¸­çš„tool_calls
    for msg in messages:
        if msg.get("role") == "assistant" and msg.get("tool_calls"):
            # è¿‡æ»¤æ‰æ²¡æœ‰å¯¹åº”ToolMessageçš„tool_calls
            valid_tool_calls: List[Dict[str, Any]] = []
            removed_calls: List[str] = []

            for tool_call in msg.get("tool_calls", []):
                tool_call_id = tool_call.get("id")
                if tool_call_id in tool_call_ids:
                    valid_tool_calls.append(tool_call)
                elif tool_call_id:
                    removed_calls.append(tool_call_id)

            # è®°å½•ä¿®å¤ä¿¡æ¯
            if removed_calls:
                print(
                    f"ğŸ”§ ä¿®å¤æ¶ˆæ¯å†å²ï¼šç§»é™¤äº† {len(removed_calls)} ä¸ªä¸å®Œæ•´çš„å·¥å…·è°ƒç”¨: {removed_calls}"
                )

            # æ›´æ–°æ¶ˆæ¯
            if valid_tool_calls:
                msg_copy = msg.copy()
                msg_copy["tool_calls"] = valid_tool_calls
                fixed_messages.append(msg_copy)
            elif msg.get("content"):  # å¦‚æœæ²¡æœ‰æœ‰æ•ˆçš„tool_callsä½†æœ‰contentï¼Œä¿ç•™æ¶ˆæ¯
                msg_copy = msg.copy()
                msg_copy.pop("tool_calls", None)  # ç§»é™¤ç©ºçš„tool_calls
                fixed_messages.append(msg_copy)
            # å¦‚æœæ—¢æ²¡æœ‰æœ‰æ•ˆtool_callsä¹Ÿæ²¡æœ‰contentï¼Œè·³è¿‡è¿™æ¡æ¶ˆæ¯
        else:
            # éassistantæ¶ˆæ¯æˆ–æ²¡æœ‰tool_callsçš„æ¶ˆæ¯ç›´æ¥ä¿ç•™
            fixed_messages.append(msg)

    return fixed_messages


async def langgraph_supervisor_agent(
    messages: List[Dict[str, Any]],
    canvas_id: str,
    session_id: str,
    tool_list: list[ToolInfo | dict],
) -> None:
    """å¤šæ™ºèƒ½ä½“å¤„ç†å‡½æ•°

    Args:
        messages: æ¶ˆæ¯å†å²
        canvas_id: ç”»å¸ƒID
        session_id: ä¼šè¯ID
        text_model: æ–‡æœ¬æ¨¡å‹é…ç½®
        tool_list: å·¥å…·æ¨¡å‹é…ç½®åˆ—è¡¨ï¼ˆå›¾åƒæˆ–è§†é¢‘æ¨¡å‹ï¼‰
        system_prompt: ç³»ç»Ÿæç¤ºè¯
    """
    try:
        # 0. ä¿®å¤æ¶ˆæ¯å†å²
        # fixed_messages = _fix_chat_history(messages)

        # 2. æ–‡æœ¬æ¨¡å‹
        # text_model_instance = _create_text_model(text_model)

        # 3. åˆ›å»ºæ™ºèƒ½ä½“
        # agents = AgentManager.create_agents(
        #     text_model_instance,
        #     tool_list,  # ä¼ å…¥æ‰€æœ‰æ³¨å†Œçš„å·¥å…·
        #     system_prompt or ""
        # )
        # agent_names = [agent.name for agent in agents]
        # print('ğŸ‘‡agent_names', agent_names)
        # last_agent = AgentManager.get_last_active_agent(
        #     fixed_messages, agent_names)
        #
        # print('ğŸ‘‡last_agent', last_agent)

        # 4. åˆ›å»ºæ™ºèƒ½ä½“ç¾¤ç»„
        # swarm = create_swarm(
        #     agents=agents,  # type: ignore
        #     default_active_agent=last_agent if last_agent else agent_names[0]
        # )

        # 5. åˆ›å»ºä¸Šä¸‹æ–‡
        context = {
            "canvas_id": canvas_id,
            "session_id": session_id,
            "configurable": {"thread_id": session_id},
            "tool_list": tool_list,
        }

        # TODO åˆ›å»ºæ™ºèƒ½ä½“
        if settings.repo_type == "postgres":

            db_uri = f"postgresql://{settings.postgres.username}:{settings.postgres.password.get_secret_value()}@{settings.postgres.host}:{settings.postgres.port}/{settings.postgres.database}"
            # db_uri = settings.postgres_dsn
            from langgraph.checkpoint.postgres.aio import AsyncPostgresSaver

            async with AsyncPostgresSaver.from_conn_string(db_uri) as checkpointer:
                agent = build_creative_assistant(checkpointer=checkpointer)
                # 6. æµå¤„ç†
                processor = StreamProcessor(session_id, send_to_websocket)  # type: ignore
                await processor.process_stream(
                    agent,
                    messages,
                    context,
                )
        else:
            agent = build_creative_assistant(checkpointer=memory_checkpointer)
            # 6. æµå¤„ç†
            processor = StreamProcessor(session_id, send_to_websocket)  # type: ignore
            await processor.process_stream(
                agent,
                messages,
                context,
            )

    except Exception as e:
        await _handle_error(e, session_id)


def _create_text_model(text_model: ModelInfo) -> Any:
    """åˆ›å»ºè¯­è¨€æ¨¡å‹å®ä¾‹"""
    model = text_model.get("model")
    provider = text_model.get("provider")
    url = text_model.get("url")
    api_key = settings.providers.openai.api_key

    # TODO: Verify if max token is working
    # max_tokens = text_model.get('max_tokens', 8148)

    if provider == "ollama":
        pass

    else:
        # Create httpx client with SSL configuration for ChatOpenAI
        print(url)
        print(api_key)
        return ChatOpenAI(
            model=model,
            api_key=api_key,  # type: ignore
            timeout=300,
            base_url=url,
            temperature=0,
            # max_tokens=max_tokens, # TODO: æš‚æ—¶æ³¨é‡Šæ‰æœ‰é—®é¢˜çš„å‚æ•°
        )


async def _handle_error(error: Exception, session_id: str) -> None:
    """å¤„ç†é”™è¯¯"""
    print("Error in langgraph_agent", error)
    tb_str = traceback.format_exc()
    print(f"Full traceback:\n{tb_str}")
    traceback.print_exc()

    await send_to_websocket(
        session_id, cast(Dict[str, Any], {"type": "error", "error": str(error)})
    )
